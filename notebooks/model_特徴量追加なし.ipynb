{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ノートブックの概要\n",
    "- 特徴量は入力データそのまま\n",
    "- モデルはlightGBM\n",
    "- パラメータチューニングなし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_cols(100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込みから前処理まで\n",
    "\n",
    "# データを読み込む\n",
    "train = pl.read_csv(\"../data/input/train.csv\")\n",
    "test = pl.read_csv(\"../data/input/test.csv\")\n",
    "sample_submit = pl.read_csv(\"../data/input/sample_submit.csv\", has_header = False)\n",
    "\n",
    "# IDと日時を分散する\n",
    "train = train.insert_column(0, train[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype = pl.Date))\n",
    "test = test.insert_column(0, test[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype = pl.Date))\n",
    "\n",
    "# 休業日(close = 1)(と、お盆だけど休業していなくて結局引っ越し数0だった日)を分離する\n",
    "train = train.filter(\n",
    "    (pl.col(\"close\") != 1)\n",
    "    & (pl.col(\"id\") != \"2010-08-18\")\n",
    "    & (pl.col(\"id\") != \"2011-08-14\")\n",
    ")\n",
    "test_close = test.filter(pl.col(\"close\") == 1)[[\"id\"]]\n",
    "test_close = test_close.with_columns(pl.Series(\"y\", [0.0] * len(test_close)))\n",
    "test = test.filter(pl.col(\"close\") != 1)\n",
    "\n",
    "# 目的変数を対数変換する\n",
    "train = train.insert_column(3, train[\"y\"].log().alias(\"y_ln\"))\n",
    "\n",
    "# closeをカラムごと削除\n",
    "train = train.drop(\"close\")\n",
    "test = test.drop(\"close\")\n",
    "\n",
    "# 2010年は料金区分に関する情報が欠損しているので学習から削除\n",
    "train = train.filter(pl.col(\"datetime\") >= date(2011, 1, 1))\n",
    "\n",
    "print(train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prophetによるベースライン作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarsのdatetime型をpandasのdatetime型に変換する必要がある\n",
    "# 訓練データ\n",
    "train_pandas = (\n",
    "    train\n",
    "    .select([\"datetime\", \"y_ln\"])\n",
    "    .rename({\"datetime\": \"ds\", \"y_ln\": \"y\"})\n",
    "    .to_pandas()\n",
    ")\n",
    "# テストデータ\n",
    "test_pandas = (\n",
    "    test\n",
    "    .select([\"datetime\"])\n",
    "    .rename({\"datetime\": \"ds\"})\n",
    "    .to_pandas()\n",
    ")\n",
    "# 学習\n",
    "model = Prophet()\n",
    "model.fit(train_pandas)\n",
    "\n",
    "# 予測\n",
    "forecast_train = model.predict(train_pandas)\n",
    "forecast_test = model.predict(test_pandas)\n",
    "\n",
    "# 予測結果の可視化\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=(12, 5),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "ax.set_title(\"Prophetによる予測（Train=青, Test=赤）(縦軸：y_ln、横軸：datetime)\")\n",
    "\n",
    "# train側は Prophet の標準描画（青・点群付き）\n",
    "model.plot(model.predict(train_pandas), ax=ax)\n",
    "\n",
    "# test側は後から重ね描き（赤）\n",
    "ax.plot(\n",
    "    forecast_test[\"ds\"], forecast_test[\"yhat\"],\n",
    "    color=\"red\", linewidth=2, label=\"Test yhat\"\n",
    ")\n",
    "ax.fill_between(\n",
    "    forecast_test[\"ds\"],\n",
    "    forecast_test[\"yhat_lower\"], forecast_test[\"yhat_upper\"],\n",
    "    color=\"red\", alpha=0.2, label=\"Test interval\"\n",
    ") \n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上手い感じにトレンドを捉えている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推定値の算出\n",
    "forecast_train_pl = pl.Series(\"y_ln_prophet\", forecast_train[\"yhat\"].values)\n",
    "forecast_test_pl = pl.Series(\"y_ln_prophet\", forecast_test[\"yhat\"].values)\n",
    "\n",
    "# 推定値をDataFrameにまとめる\n",
    "train = train.insert_column(4, forecast_train_pl)\n",
    "test = test.insert_column(3, forecast_test_pl)\n",
    "\n",
    "# 残差列を追加\n",
    "train = train.with_columns(\n",
    "    (train[\"y_ln\"] - train[\"y_ln_prophet\"]).alias(\"y_ln_difference\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量追加なし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習ライブラリと親和性の高いPandasに変換する\n",
    "train_pandas = train.to_pandas().set_index(\"id\")\n",
    "\n",
    "# 目的変数と特徴量\n",
    "target_column = \"y_ln_difference\"\n",
    "feature_columns = [\"client\", \"price_am\", \"price_pm\"]\n",
    "\n",
    "# 今回は時系列予測なので、訓練データと評価データを分割する際に、時系列の順番を考慮する必要がある\n",
    "# 今回は、2015年1月1日を境に訓練データと評価データを分割する\n",
    "# 訓練データと検証データを期間で分割\n",
    "train_temp = train_pandas[train_pandas[\"datetime\"] < \"2015-01-01\"]\n",
    "valid_temp = train_pandas[train_pandas[\"datetime\"] >= \"2015-01-01\"]\n",
    "\n",
    "# 説明変数と目的変数を分割\n",
    "X_train, y_train = train_temp[feature_columns], train_temp[target_column]\n",
    "X_valid, y_valid = valid_temp[feature_columns], valid_temp[target_column]\n",
    "\n",
    "# 学習\n",
    "model = GradientBoostingRegressor(random_state = 1192).fit(X_train, y_train)\n",
    "\n",
    "# 予測(モデルの予測値をベースラインであるy_ln_prophetに足した後、対数変換を逆変換)\n",
    "y_pred_train = np.exp(model.predict(X_train) + train_temp[\"y_ln_prophet\"])\n",
    "y_pred_valid = np.exp(model.predict(X_valid) + valid_temp[\"y_ln_prophet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可視化\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=2,\n",
    "    height_ratios=[1, 1, 1], width_ratios=[2, 1],\n",
    "    figsize=(15, 12)\n",
    ")\n",
    "\n",
    "g_time_train = sns.lineplot(data = train_pandas, x=\"datetime\", y=\"y\", ax=axes[0, 0])\n",
    "g_predict_train = sns.lineplot(data = train_temp, x=\"datetime\", y=y_pred_train, ax=axes[0, 0])\n",
    "g_predict_valid = sns.lineplot(data = valid_temp, x=\"datetime\", y=y_pred_valid, ax=axes[0, 0])\n",
    "\n",
    "g_time_hist_train = sns.histplot(data = train_pandas, x=\"y\", bins=50, ax=axes[0, 1])\n",
    "g_predict_hist_train = sns.histplot(data = train_temp, x=y_pred_train, bins=50, ax=axes[0, 1])\n",
    "g_predict_hist_valid = sns.histplot(data = valid_temp, x=y_pred_valid, bins=50, ax=axes[0, 1])\n",
    "\n",
    "# 残差の確認\n",
    "g_diff_train = sns.scatterplot(data = train_temp, x=\"datetime\", y=train_temp[\"y\"] - y_pred_train, marker = \"+\", ax=axes[1, 0])\n",
    "g_diff_valid = sns.scatterplot(data = valid_temp, x=\"datetime\", y=valid_temp[\"y\"] - y_pred_valid, marker = \"+\", ax=axes[1, 0])\n",
    "axes[1, 0].set_ylabel(\"残差\")\n",
    "\n",
    "g_hist_diff_train = sns.histplot(data = train_temp, x=train_temp[\"y\"] - y_pred_train, bins=50, ax=axes[1, 1])\n",
    "g_hist_diff_valid = sns.histplot(data = valid_temp, x=valid_temp[\"y\"] - y_pred_valid, bins=50, ax=axes[1, 1])\n",
    "\n",
    "# 特徴量重要度\n",
    "g_importance = sns.barplot(x=model.feature_importances_, y=feature_columns, ax=axes[2, 0])\n",
    "g_importance.set_title(\"特徴量重要度\")\n",
    "\n",
    "axes[2, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 予測精度の確認\n",
    "print(\"訓練データの評価関数:\", np.round(mean_absolute_error(train_temp[\"y\"], y_pred_train), decimals = 7))# 小数第7位はコンペスコアの有効数字\n",
    "print(\"評価データの評価関数:\", np.round(mean_absolute_error(valid_temp[\"y\"], y_pred_valid), decimals = 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 下部が上手く予測出来ていない\n",
    "  - 何によるものなのかは不明だが、日時に関する特徴量を何も渡していないのでまともに予測できるはずもないだろう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上昇傾向は上手く捉えられている(prophetのおかげかな)  \n",
    "実際、残差の分布については何とか揃えられている  \n",
    "引っ越し数yが低い場所が上手く予測できていない。何だか、下限が一つの曲線で抑えられてしまっている？  \n",
    "改めて、やっぱ特徴量が少なすぎる。もっといろいろ増やそう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提出データ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 提出前に、全ての訓練データを使って学習させておく\n",
    "# X, y = train_pandas[feature_columns], train_pandas[target_column]\n",
    "# model = GradientBoostingRegressor(random_state = 1192).fit(X, y)\n",
    "\n",
    "# # 機械学習ライブラリと親和性の高いPandasに変換する\n",
    "# test_pandas = test.to_pandas().set_index(\"id\")\n",
    "\n",
    "# # 説明変数の分割\n",
    "# X_test = test_pandas[feature_columns]\n",
    "\n",
    "# # 予測\n",
    "# y_pred_test = np.exp(model.predict(X_test) + test_pandas[\"y_ln_prophet\"])\n",
    "\n",
    "# # 提出用DataFrame\n",
    "# submit = pl.DataFrame({\n",
    "#     \"id\": X_test.index.values,\n",
    "#     \"y\": y_pred_test.values\n",
    "# })\n",
    "\n",
    "# # 退避していた休業日のデータを結合\n",
    "# submit = pl.concat(\n",
    "#     [submit, test_close],\n",
    "#     how = \"vertical_relaxed\"\n",
    "# ).sort(\"id\")\n",
    "\n",
    "# # 提出ファイルを保存する\n",
    "# # submit.write_csv(\"../data/output/submit_original_features_gbt_default_prm.csv\", include_header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # テストデータに対する予測の可視化\n",
    "# fig, axes = plt.subplots(\n",
    "#     nrows=1, ncols=2,\n",
    "#     height_ratios=[1], width_ratios=[2, 1],\n",
    "#     figsize=(15, 4)\n",
    "# )\n",
    "\n",
    "# g_time_train = sns.lineplot(data = train_pandas, x=\"datetime\", y=\"y\", ax=axes[0])\n",
    "# g_time_test = sns.lineplot(data = test_pandas, x=\"datetime\", y=y_pred_test, ax=axes[0])\n",
    "\n",
    "# g_hist_train = sns.histplot(data = train_pandas, x=\"y\", ax=axes[1])\n",
    "# g_hist_test = sns.histplot(data = test_pandas, x=y_pred_test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考サイト  \n",
    "[コンペサイト アップル 引越し需要予測](https://signate.jp/competitions/269/data)  \n",
    "[SIGNATE SOTA アップル 引越し需要予測 備忘録](https://zenn.dev/tremendous1192/articles/ea6e73359ee764)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# htmlに変換したものを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from pathlib import Path\n",
    "\n",
    "# base_name = \"model_特徴量追加なし\"\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# output_dir = Path(\"html\")\n",
    "# output_file = f\"{base_name}_{timestamp}\"\n",
    "\n",
    "# !jupyter nbconvert --to html EDA.ipynb --output \"{output_file}\" --output-dir \"{output_dir}\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb",
   "notebook_metadata_filter": "kernelspec,jupytext"
  },
  "kernelspec": {
   "display_name": "venv_apple_hikkosi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
