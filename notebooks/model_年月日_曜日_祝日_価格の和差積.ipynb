{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ノートブックの概要\n",
    "- 特徴量を追加\n",
    "- モデルはlightGBM\n",
    "- パラメータチューニングなし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_cols(100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import date\n",
    "import jpholiday\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込みから前処理まで\n",
    "\n",
    "# データ読み込み\n",
    "train = pl.read_csv(\"../data/input/train.csv\")\n",
    "test = pl.read_csv(\"../data/input/test.csv\")\n",
    "sample_submit = pl.read_csv(\"../data/input/sample_submit.csv\", has_header = False)\n",
    "\n",
    "# id列関連の前処理\n",
    "# 元の\"datetime\" 列(str型)のコピーを \"id\" という名前で新しい列として先頭に追加する。その後、\"datetime\" 列をdate型に変換する。\n",
    "train = train.insert_column(0, train[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype = pl.Date))\n",
    "test = test.insert_column(0, test[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype = pl.Date))\n",
    "\n",
    "# 休業日(close = 1)(と、お盆だけど休業していなくて結局引っ越し数0だった日)を分離する\n",
    "train = train.filter(\n",
    "    (pl.col(\"close\") != 1)\n",
    "    & (pl.col(\"id\") != \"2010-08-18\")\n",
    "    & (pl.col(\"id\") != \"2011-08-14\")\n",
    ")\n",
    "test_close = test.filter(pl.col(\"close\") == 1)[[\"id\"]]\n",
    "test_close = test_close.with_columns(pl.Series(\"y\", [0.0] * len(test_close)))\n",
    "test = test.filter(pl.col(\"close\") != 1)\n",
    "\n",
    "# closeをカラムごと削除\n",
    "train = train.drop(\"close\")\n",
    "test = test.drop(\"close\")\n",
    "\n",
    "# region コンペへのデータ提出などの際は、最終的には以下の通り結合する\n",
    "# pl.concat(\n",
    "#     [submit, test_close],\n",
    "#     how = \"vertical_relaxed\"\n",
    "# ).sort(\"id\")\n",
    "# endregion\n",
    "\n",
    "# 2010年のデータは学習から削除。料金区分に関する情報が欠損している\n",
    "train = train.filter(pl.col(\"datetime\") >= date(2011, 1, 1))\n",
    "\n",
    "# 目的変数を対数変換する\n",
    "# 現状のコードだと、trainのyに0が含まれているとエラーになる。なので休業日関連の前処理を先に行う必要がある。\n",
    "train = train.insert_column(3, train[\"y\"].log().alias(\"y_ln\"))\n",
    "\n",
    "# 前処理後のデータ確認\n",
    "print(train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prophetによるベースライン作成、残差列追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数変換した目的変数y_lnをProphetで学習させる\n",
    "\n",
    "# polarsのdatetime型をpandasのdatetime型に変換する必要がある\n",
    "# 訓練データ\n",
    "train_pandas = (\n",
    "    train\n",
    "    .select([\"datetime\", \"y_ln\"])\n",
    "    .rename({\"datetime\": \"ds\", \"y_ln\": \"y\"})\n",
    "    .to_pandas()\n",
    ")\n",
    "# テストデータ\n",
    "test_pandas = (\n",
    "    test\n",
    "    .select([\"datetime\"])\n",
    "    .rename({\"datetime\": \"ds\"})\n",
    "    .to_pandas()\n",
    ")\n",
    "# 学習\n",
    "model = Prophet()\n",
    "model.fit(train_pandas)\n",
    "\n",
    "# 予測\n",
    "forecast_train = model.predict(train_pandas)\n",
    "forecast_test = model.predict(test_pandas)\n",
    "\n",
    "# 予測結果の可視化\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=(12, 5),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "ax.set_title(\"Prophetによる予測（Train=青, Test=赤）(縦軸：y_ln、横軸：datetime)\", fontsize=16)\n",
    "\n",
    "# train側は Prophet の標準描画（青・点群付き）\n",
    "model.plot(model.predict(train_pandas), ax=ax)\n",
    "\n",
    "# test側は後から重ね描き（赤）\n",
    "ax.plot(\n",
    "    forecast_test[\"ds\"], forecast_test[\"yhat\"],\n",
    "    color=\"red\", linewidth=2, label=\"Test yhat\"\n",
    ")\n",
    "ax.fill_between(\n",
    "    forecast_test[\"ds\"],\n",
    "    forecast_test[\"yhat_lower\"], forecast_test[\"yhat_upper\"],\n",
    "    color=\"red\", alpha=0.2, label=\"Test interval\"\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推定値の算出\n",
    "forecast_train_pl = pl.Series(\"y_ln_prophet\", forecast_train[\"yhat\"].values)\n",
    "forecast_test_pl = pl.Series(\"y_ln_prophet\", forecast_test[\"yhat\"].values)\n",
    "\n",
    "# 推定値をDataFrameにまとめる\n",
    "train = train.insert_column(4, forecast_train_pl)\n",
    "test = test.insert_column(3, forecast_test_pl)\n",
    "\n",
    "# 残差列を追加\n",
    "train = train.with_columns(\n",
    "    (train[\"y_ln\"] - train[\"y_ln_prophet\"]).alias(\"y_ln_difference\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 思いつく限りの特徴量を追加\n",
    "# 今後の運用を考えると、任意の日時について自動でフラグを取得できる必要がある。要改善\n",
    "\n",
    "# 祝日\n",
    "holiday_list = []\n",
    "for pair in jpholiday.between(date(2010, 1, 1), date(2017, 12, 31)):\n",
    "    # print(pair)\n",
    "    holiday_list.append(pair[0])\n",
    "\n",
    "# その他の休日\n",
    "# GW\n",
    "# https://9rando.info/j-holiday/gw/2011/\n",
    "gw_list = [\n",
    "    date(2011, 4, 29), date(2011, 4, 30), date(2011, 5, 1),\n",
    "    date(2011, 5, 2),# 有給休暇の可能性\n",
    "    date(2011, 5, 3), date(2011, 5, 4), date(2011, 5, 5),\n",
    "\n",
    "    date(2012, 4, 28), date(2012, 4, 29), date(2012, 4, 30), date(2012, 5, 1),\n",
    "    date(2012, 5, 2),# 有休\n",
    "    date(2012, 5, 3), date(2012, 5, 4), date(2012, 5, 5), date(2012, 5, 5),\n",
    "\n",
    "    date(2013, 4, 27), date(2013, 4, 28), date(2013, 4, 29),\n",
    "    date(2013, 4, 30), date(2013, 5, 1), date(2013, 5, 2),# 有休\n",
    "    date(2013, 5, 3), date(2013, 5, 4), date(2013, 5, 5), date(2013, 5, 5), date(2013, 5, 6),\n",
    "\n",
    "    date(2014, 4, 29),\n",
    "    date(2014, 4, 30), date(2014, 5, 1), date(2014, 5, 2),# 有休\n",
    "    date(2014, 5, 3), date(2014, 5, 4), date(2014, 5, 5), date(2014, 5, 5), date(2014, 5, 6),\n",
    "\n",
    "    date(2015, 4, 29),\n",
    "    date(2015, 4, 30), date(2015, 5, 1),# 有休\n",
    "    date(2015, 5, 2), date(2015, 5, 3), date(2015, 5, 4), date(2015, 5, 5), date(2015, 5, 5), date(2015, 5, 6),\n",
    "\n",
    "    date(2016, 4, 29), date(2016, 4, 30), date(2016, 5, 1),\n",
    "    date(2016, 5, 2),# 有休\n",
    "    date(2016, 5, 3), date(2016, 5, 4), date(2016, 5, 5),\n",
    "\n",
    "    date(2017, 4, 29), date(2017, 4, 30),\n",
    "    date(2017, 5, 1), date(2017, 5, 2),# 有休\n",
    "    date(2017, 5, 3), date(2017, 5, 4), date(2017, 5, 5), date(2017, 5, 6), date(2017, 5, 7),\n",
    "]\n",
    "\n",
    "# お盆\n",
    "# https://9rando.info/j-holiday/obon/2011/\n",
    "obon_list = [\n",
    "    date(2011, 8, 13), date(2011, 8, 14), date(2011, 8, 15), date(2011, 8, 16),\n",
    "    date(2012, 8, 13), date(2012, 8, 14), date(2012, 8, 15), date(2012, 8, 16),\n",
    "    date(2013, 8, 13), date(2013, 8, 14), date(2013, 8, 15), date(2013, 8, 16),\n",
    "    date(2014, 8, 13), date(2014, 8, 14), date(2014, 8, 15), date(2014, 8, 16),\n",
    "    date(2015, 8, 13), date(2015, 8, 14), date(2015, 8, 15), date(2015, 8, 16),\n",
    "    date(2016, 8, 13), date(2016, 8, 14), date(2016, 8, 15), date(2016, 8, 16),\n",
    "    date(2017, 8, 13), date(2017, 8, 14), date(2017, 8, 15), date(2017, 8, 16),\n",
    "]\n",
    "\n",
    "# シルバーウィーク\n",
    "# https://9rando.info/j-holiday/sw/2011/\n",
    "sw_list = [\n",
    "    date(2011, 9, 17), date(2011, 9, 18), date(2011, 9, 19),\n",
    "    date(2011, 9, 20), date(2011, 9, 21), date(2011, 9, 22),# 有休\n",
    "    date(2011, 9, 23), date(2011, 9, 24), date(2011, 9, 25),\n",
    "\n",
    "    date(2012, 9, 15), date(2012, 9, 16), date(2012, 9, 17),\n",
    "    date(2012, 9, 18), date(2012, 9, 19), date(2012, 9, 20), date(2012, 9, 21),# 有休\n",
    "    date(2012, 9, 22), date(2012, 9, 23), date(2012, 9, 24),\n",
    "\n",
    "    date(2013, 9, 14),date(2013, 9, 15), date(2013, 9, 16),\n",
    "    date(2013, 9, 17), date(2013, 9, 18), date(2013, 9, 19), date(2013, 9, 20),# 有休\n",
    "    date(2013, 9, 21),date(2013, 9, 22), date(2013, 9, 23),\n",
    "\n",
    "    date(2014, 9, 13), date(2014, 9, 14),date(2014, 9, 15),\n",
    "    date(2014, 9, 16), date(2014, 9, 17), date(2014, 9, 18), date(2014, 9, 19),# 有休\n",
    "    date(2014, 9, 20), date(2014, 9, 21),date(2014, 9, 22),\n",
    "\n",
    "    date(2015, 9, 19), date(2015, 9, 20), date(2015, 9, 21),\n",
    "    date(2015, 9, 22), date(2015, 9, 23),\n",
    "\n",
    "    date(2016, 9, 17), date(2016, 9, 18), date(2016, 9, 19),\n",
    "    date(2016, 9, 20), date(2016, 9, 21),# 有休\n",
    "    date(2016, 9, 22),\n",
    "\n",
    "    date(2017, 9, 16), date(2017, 9, 17), date(2017, 9, 18),\n",
    "    date(2017, 9, 19), date(2017, 9, 20), date(2017, 9, 21), date(2017, 9, 22),# 有休\n",
    "    date(2017, 9, 23), date(2017, 9, 24),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    return(\n",
    "        df\n",
    "        # 日付の基本要素の追加\n",
    "        .with_columns([\n",
    "            # 年、四半期、月\n",
    "            pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            pl.col(\"datetime\").dt.quarter().alias(\"quarter\"),\n",
    "            pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "            # 年始から数えて何週目か\n",
    "            pl.col(\"datetime\").dt.week().alias(\"week\"),\n",
    "            # 年始から数えて何日目か\n",
    "            pl.col(\"datetime\").dt.ordinal_day().alias(\"ordinal_day\"),\n",
    "            # その月の何日か\n",
    "            pl.col(\"datetime\").dt.day().alias(\"day\"),\n",
    "            # その月の何週目か\n",
    "            (pl.col(\"datetime\").dt.day() // 7 + 1).alias(\"week_of_month\"),\n",
    "            # 曜日(月曜日が1、日曜日が6)\n",
    "            pl.col(\"datetime\").dt.weekday().alias(\"day_of_week\"),\n",
    "        ])\n",
    "        # 四半期はじめ・終わり、月はじめ・終わりのフラグ\n",
    "        .with_columns([\n",
    "            pl.when((pl.col(\"month\").is_in([1, 4, 7, 10])) & (pl.col(\"day\") == 1)).then(1).otherwise(0)\n",
    "            .alias(\"quarter_start\"),\n",
    "            pl.when((pl.col(\"month\").is_in([3, 6, 9, 12])) & (pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end())).then(1).otherwise(0)\n",
    "            .alias(\"quarter_end\"),\n",
    "            pl.when(pl.col(\"day\") == 1).then(1).otherwise(0)\n",
    "            .alias(\"month_start\"),\n",
    "            pl.when(pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end()).then(1).otherwise(0)\n",
    "            .alias(\"month_end\"),\n",
    "        ])\n",
    "        # 祝日・休日・土日フラグ\n",
    "        .with_columns([\n",
    "            pl.when(pl.col(\"datetime\").is_in(holiday_list)).then(1).otherwise(0)\n",
    "            .alias(\"holiday\"),\n",
    "            pl.when(pl.col(\"datetime\").is_in(gw_list)).then(1).otherwise(0)\n",
    "            .alias(\"GW\"),\n",
    "            pl.when(pl.col(\"datetime\").is_in(sw_list)).then(1).otherwise(0)\n",
    "            .alias(\"SW\"),\n",
    "            pl.when(pl.col(\"datetime\").is_in(obon_list)).then(1).otherwise(0)\n",
    "            .alias(\"obon\"),\n",
    "            pl.when(pl.col(\"datetime\").dt.weekday() >= 6).then(1).otherwise(0)\n",
    "            .alias(\"sat_sun\"),\n",
    "        ])\n",
    "        # 価格の和・差・積\n",
    "        .with_columns([\n",
    "            (pl.col(\"price_am\") + pl.col(\"price_pm\")).alias(\"price_sum\"),\n",
    "            (pl.col(\"price_am\") - pl.col(\"price_pm\")).alias(\"price_difference\"),\n",
    "            # price = -1が欠損、price = 0は最安価格であった。price同士をそのまま乗算しまうと最安値のときに必ず積が0になってしまうので都合が良くない\n",
    "            # price + 1とすることでこれを回避する。なお、欠損がある場合は積は必ず0となる。これはこれで良いフラグかもしれない？\n",
    "            ((pl.col(\"price_am\") + 1) * (pl.col(\"price_pm\") + 1)).alias(\"price_product\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "del holiday_list, gw_list, sw_list, obon_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習ライブラリと親和性の高いPandasに変換する\n",
    "train_pandas = train.to_pandas().set_index(\"id\")\n",
    "\n",
    "# 目的変数と特徴量\n",
    "target_column = \"y_ln_difference\"\n",
    "feature_columns = [\n",
    "    'client',\n",
    "    'price_am',\n",
    "    'price_pm',\n",
    "    'year',\n",
    "    'quarter',\n",
    "    'month',\n",
    "    'week',\n",
    "    'ordinal_day',\n",
    "    'day',\n",
    "    'week_of_month',\n",
    "    'day_of_week',\n",
    "    'quarter_start',\n",
    "    'quarter_end',\n",
    "    'month_start',\n",
    "    'month_end',\n",
    "    'holiday',\n",
    "    'GW',\n",
    "    'SW',\n",
    "    'obon',\n",
    "    'sat_sun',\n",
    "    'price_sum',\n",
    "    'price_difference',\n",
    "    'price_product'\n",
    "]\n",
    "\n",
    "# 今回は時系列予測なので、訓練データと評価データを分割する際に、時系列の順番を考慮する必要がある\n",
    "# 今回は、2015年1月1日を境に訓練データと評価データを分割する\n",
    "# 訓練データと検証データを期間で分割\n",
    "train_temp = train_pandas[train_pandas[\"datetime\"] < \"2015-01-01\"]\n",
    "valid_temp = train_pandas[train_pandas[\"datetime\"] >= \"2015-01-01\"]\n",
    "\n",
    "# 説明変数と目的変数を分割\n",
    "X_train, y_train = train_temp[feature_columns], train_temp[target_column]\n",
    "X_valid, y_valid = valid_temp[feature_columns], valid_temp[target_column]\n",
    "\n",
    "# 学習\n",
    "model = GradientBoostingRegressor(random_state = 1192).fit(X_train, y_train)\n",
    "\n",
    "# 予測(モデルの予測値をベースラインであるy_ln_prophetに足した後、対数変換を逆変換)\n",
    "y_pred_train = np.exp(model.predict(X_train) + train_temp[\"y_ln_prophet\"])\n",
    "y_pred_valid = np.exp(model.predict(X_valid) + valid_temp[\"y_ln_prophet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=2,\n",
    "    height_ratios=[1, 1, 1], width_ratios=[2, 1],\n",
    "    figsize=(15, 12),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"モデル学習後の予測結果(元データ, 学習データ, 検証データ)\", fontsize=16)\n",
    "\n",
    "palette = sns.color_palette(\"tab10\")\n",
    "\n",
    "axes[0, 0].set_title(\"推移\")\n",
    "sns.lineplot(data = train_pandas, x=\"datetime\", y=\"y\", color=palette[0], ax=axes[0, 0])\n",
    "sns.lineplot(data = train_temp, x=\"datetime\", y=y_pred_train, label=\"train_pred\", color=palette[1], ax=axes[0, 0])\n",
    "sns.lineplot(data = valid_temp, x=\"datetime\", y=y_pred_valid, label=\"valid_pred\", color=palette[2], ax=axes[0, 0])\n",
    "\n",
    "axes[0, 1].set_title(\"分布\")\n",
    "sns.histplot(data = train_pandas, x=\"y\", binwidth=2, color=palette[0], ax=axes[0, 1])\n",
    "sns.histplot(data = train_temp, x=y_pred_train, binwidth=2, label=\"train_pred\", color=palette[1], ax=axes[0, 1])\n",
    "sns.histplot(data = valid_temp, x=y_pred_valid, binwidth=2, label=\"valid_pred\", color=palette[2], ax=axes[0, 1])\n",
    "\n",
    "axes[1, 0].set_title(\"予測誤差\")\n",
    "axes[1, 0].set_ylabel(\"誤差\")\n",
    "sns.scatterplot(data = train_temp, x=\"datetime\", y=train_temp[\"y\"] - y_pred_train, marker = \"+\", label=\"train_pred_err\", color=palette[1], ax=axes[1, 0])\n",
    "sns.scatterplot(data = valid_temp, x=\"datetime\", y=valid_temp[\"y\"] - y_pred_valid, marker = \"+\", label=\"valid_pred_err\", color=palette[2], ax=axes[1, 0])\n",
    "\n",
    "axes[1, 1].set_title(\"予測誤差の分布\")\n",
    "sns.histplot(data = train_temp, x=train_temp[\"y\"] - y_pred_train, binwidth=2, color=palette[1], ax=axes[1, 1])\n",
    "sns.histplot(data = valid_temp, x=valid_temp[\"y\"] - y_pred_valid, binwidth=2, color=palette[2], ax=axes[1, 1])\n",
    "\n",
    "axes[2, 0].set_title(\"特徴量重要度\")\n",
    "sns.barplot(x=model.feature_importances_, y=feature_columns, ax=axes[2, 0])\n",
    "\n",
    "axes[2, 1].axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 予測精度の確認\n",
    "print(\"訓練データの評価関数:\", np.round(mean_absolute_error(train_temp[\"y\"], y_pred_train), decimals = 7))# 小数第7位はコンペスコアの有効数字\n",
    "print(\"評価データの評価関数:\", np.round(mean_absolute_error(valid_temp[\"y\"], y_pred_valid), decimals = 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 予測値のベースラインっぽいのが消えて、引っ越し数の低いところに対しても予測できるようになった\n",
    "- ordinal_dayが強い。年始から数えて何日かなので、時期を表しているのだろう。\n",
    "- ただ本モデルを実用することを考えると、ピークへの追随が弱いのが気になる。これでは、「特に繁忙期にどれくらいの需要が来そうか」の予測精度としては弱いか…？\n",
    "- 改善のためには、学習の際のスコアを変えてあげれば良いのだろうか？どんなものがあるだろうか？\n",
    "- 現状だと、MSEを使って学習をさせている。既に適切な指標を使っているはずではあるが…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提出データ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出前に、全ての訓練データを使って学習させておく\n",
    "X, y = train_pandas[feature_columns], train_pandas[target_column]\n",
    "model = GradientBoostingRegressor(random_state = 1192).fit(X, y)\n",
    "\n",
    "# 機械学習ライブラリと親和性の高いPandasに変換する\n",
    "test_pandas = test.to_pandas().set_index(\"id\")\n",
    "\n",
    "# 説明変数の分割\n",
    "X_test = test_pandas[feature_columns]\n",
    "\n",
    "# 予測\n",
    "y_pred_test = np.exp(model.predict(X_test) + test_pandas[\"y_ln_prophet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynbname\n",
    "from pathlib import Path\n",
    "\n",
    "# 提出用DataFrame\n",
    "submit = pl.DataFrame({\n",
    "    \"id\": X_test.index.values,\n",
    "    \"y\": y_pred_test.values\n",
    "})\n",
    "\n",
    "# 退避していた休業日のデータを結合\n",
    "submit = pl.concat(\n",
    "    [submit, test_close],\n",
    "    how = \"vertical_relaxed\"\n",
    ").sort(\"id\")\n",
    "\n",
    "notebook_name = ipynbname.name()\n",
    "output_path = Path(\"../data/output\") / f\"submit_{notebook_name}.csv\"\n",
    "\n",
    "# 提出ファイルを保存する\n",
    "submit.write_csv(output_path, include_header = False)\n",
    "print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(12, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"テストデータに対する予測\")\n",
    "\n",
    "ax=axes[0].set_title(\"推移\")\n",
    "sns.lineplot(data = train_pandas, x=\"datetime\", y=\"y\", ax=axes[0])\n",
    "sns.lineplot(data = test_pandas, x=\"datetime\", y=y_pred_test, ax=axes[0])\n",
    "\n",
    "ax=axes[1].set_title(\"分布\")\n",
    "sns.histplot(data = train_pandas, x=\"y\", binwidth=2, ax=axes[1])\n",
    "sns.histplot(data = test_pandas, x=y_pred_test, binwidth=2, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考サイト  \n",
    "[コンペサイト アップル 引越し需要予測](https://signate.jp/competitions/269/data)  \n",
    "[SIGNATE SOTA アップル 引越し需要予測 備忘録](https://zenn.dev/tremendous1192/articles/ea6e73359ee764)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今後は汎化性能を向上させたい。今は検証データのセットが一つだけ。訓練データに対するスコアと検証データに対する精度の差が激しい。  \n",
    "KFold法みたいなやつを行って汎化性能を上げたいが、時系列予測なので分け方に気をつける必要がある。  \n",
    "時系列予測だと、TimeSeriesSplitとかWalk Forwar Validationとかいうのが使われるらしい。  \n",
    "他にも、パラメータチューニングも未実施なので、その辺りの取り組み余地はある  \n",
    "\n",
    "ただ、250409 11:47 コンペのスコア：8.5537881であり、現時点で十分な精度がでているとも言える。  \n",
    "これ以上の精度向上を求めるより、別の所(顧客の要件を満たす)に注力したほうが良いかも知れない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "てかそういえば、あまり気にしてこなかったけど、この周期的な細かいギザギザは何によって生まれているんだろう？土日とか？  \n",
    "確認してみても良いかも知れない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# htmlに変換したものを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# from pathlib import Path\n",
    "\n",
    "# base_name = \"model_年・月・日・曜日・祝日・価格の和差積\"\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# output_dir = Path(\"html\")\n",
    "# output_file = f\"{base_name}_{timestamp}\"\n",
    "\n",
    "# !jupyter nbconvert --to html EDA.ipynb --output \"{output_file}\" --output-dir \"{output_dir}\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb",
   "notebook_metadata_filter": "kernelspec,jupytext"
  },
  "kernelspec": {
   "display_name": "venv_apple_hikkosi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
