{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ノートブックの概要\n",
    "EDA及び、前処理がちゃんと動きそうかの確認のためのノートブック。以下のことを行っている\n",
    "- データ読み込んでみる\n",
    "- 時系列データを可視化\n",
    "- 時間軸をどこで区切るべきか（年？年度？）\n",
    "- 緩やかな変動を捉える（prophet）\n",
    "  - トレンドとの残差を確認\n",
    "- 引っ越し件数が0の部分（＝休業日と判明）\n",
    "- clientフラグについて\n",
    "- 料金区分（午前、午後）\n",
    "  - 料金区分（price_am, price_pm）が3以上のものを詳しく見てみる\n",
    "- 数値変換を試す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "pl.Config.set_tbl_cols(100)\n",
    "pl.Config.set_tbl_width_chars(200)\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import japanize_matplotlib\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()  # github pages 対応\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from datetime import date\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import jpholiday\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ読み込んでみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(\"../data/input/train.csv\")\n",
    "test = pl.read_csv(\"../data/input/test.csv\")\n",
    "sample_submit = pl.read_csv(\"../data/input/sample_submit.csv\", has_header=False)\n",
    "\n",
    "print(\"train\\n\", train)\n",
    "print(\"test\\n\", test)\n",
    "print(\"sample_submit\\n\", sample_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの読み方について  \n",
    "\n",
    "例えば  \n",
    "│datetime   | y   | client | close | price_am | price_pm |\n",
    "| ---- | ---- | ---- | ---- | ---- | ---- |\n",
    "│2016-03-28 | 86  | 1      | 0     | 4        | 4        │  \n",
    "\n",
    "といったとき。  \n",
    "これは、  \n",
    "日時「2016-03-28」について、この日は  \n",
    "合計引っ越し数は「86件」  \n",
    "法人が絡む特殊な引越し日フラグは「あり」  \n",
    "この日の午前料金区分は「4」  \n",
    "この日の午後料金区分は「4」  \n",
    "といった意味っぽい  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDとして使用されているdatetimeカラムを文字列型と日付型に分離\n",
    "# カラムの役割を分散することでコードエラーを発生しにくくする\n",
    "train = train.insert_column(0, train[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype=pl.Date))\n",
    "test = test.insert_column(0, test[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype=pl.Date))\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データの散布図行列\n",
    "g = sns.pairplot(\n",
    "    train.select(cs.exclude(\"id\")).to_pandas(), \n",
    "    plot_kws={\"alpha\": 0.5, \"s\": 10}, \n",
    "    diag_kws={\"alpha\": 0.7, \"bins\": 10},\n",
    ")\n",
    "g.figure.set_size_inches(8, 8)\n",
    "g.figure.suptitle(\"特徴量間のペアプロット\", y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時系列データを可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 歪度と尖度を計算\n",
    "skew = stats.skew(train[\"y\"])\n",
    "kurt = stats.kurtosis(train[\"y\"])\n",
    "\n",
    "# 可視化\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(12, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"引っ越し数yの推移と分布\")\n",
    "\n",
    "axes[0].set_title(\"推移\")\n",
    "sns.lineplot(data = train, x=\"datetime\", y=\"y\", ax=axes[0])\n",
    "\n",
    "axes[1].set_title(\"分布\")\n",
    "sns.histplot(data = train, x=\"y\", ax=axes[1])\n",
    "axes[1].text(0.6, 0.8,\n",
    "                f\"skewness={skew:.2f}\\nkurtosis={kurt:.2f}\",\n",
    "                fontsize=12,\n",
    "                transform=axes[1].transAxes)\n",
    "\n",
    "plt.show()\n",
    "del skew, kurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繁忙期を抜き出して見てみる\n",
    "train = train.with_columns(\n",
    "    (\n",
    "        ((pl.col(\"datetime\").dt.month() == 3) | (pl.col(\"datetime\").dt.month() == 4))\n",
    "    ).alias(\"is_busy\")\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(12, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"引っ越し数yの推移と分布（繁忙期・非繁忙期）\")\n",
    "\n",
    "axes[0].set_title(\"推移\")\n",
    "sns.lineplot(data = train, x=\"datetime\", y=\"y\", hue=\"is_busy\", ax=axes[0])\n",
    "\n",
    "axes[1].set_title(\"分布\")\n",
    "sns.histplot(data = train, x=\"y\", hue=\"is_busy\", ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフについてのコメント  \n",
    "- 引越し数は緩やかに増加傾向。ビジネス的には喜ばしいが、未来の需要予測というタスクにおいては注意が必要\n",
    "  - 機械学習モデルは訓練データとテストデータの目的変数の分布が等しいことを前提としているため、これが変化すると上手く予測できない\n",
    "  - 例えば、2011年データをそのまま学習させて2012年の引越し数を予測すると、予測値は実際よりも小さく見積もられてしまうものと予想される\n",
    "  - この緩やかな増加傾向を別モデルで捉えてやり、その差分を機械学習モデルに学習させるのが良いだろう\n",
    "- 繁忙期(3~4月)は他の時期と比べて明確に異なりそう(大きなピークとなっている)\n",
    "- 引っ越し数yが0の日がある\n",
    "- yの分布は非対称 → 数値変換すると良いかも？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ここらへんで一度、ydata-profillingでレポートも出力させておく？ライブラリのインストールが必要。ipywigetsも必要。\n",
    "# import pandas as pd\n",
    "# from ydata_profiling import ProfileReport\n",
    "# data_train = pd.read_csv('titanic_train.csv')\n",
    "# profile = ProfileReport(data_train, title=\"Profiling Report\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 時間軸をどこで区切るべきか(年？年度？)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年ごとで分けるか？年度ごとで分けるか？\n",
    "train = (\n",
    "    train\n",
    "    .with_columns([\n",
    "        pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "        pl.when(pl.col(\"datetime\").dt.month() <= 3).then(pl.col(\"datetime\").dt.year() - 1)\n",
    "        .otherwise(pl.col(\"datetime\").dt.year())\n",
    "        .alias(\"fy\")\n",
    "    ])\n",
    ")\n",
    "print(train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=1,\n",
    "    height_ratios=[1, 1], width_ratios=[1],\n",
    "    figsize=(8, 6),\n",
    "    constrained_layout=True,    \n",
    ")\n",
    "fig.suptitle(\"引っ越し数yの推移　年・年度別での比較\")\n",
    "\n",
    "axes[0].set_title(\"年区切り\")\n",
    "sns.lineplot(data = train, x=\"datetime\", y=\"y\", hue=\"year\", palette=\"deep\", ax=axes[0])\n",
    "\n",
    "axes[1].set_title(\"年度区切り\")\n",
    "sns.lineplot(data = train, x=\"datetime\", y=\"y\", hue=\"fy\", palette=\"deep\", ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフへのコメント  \n",
    "- 年度で分けると、繁忙期(3~4月)のピークが分割されてしまい分析が難しくなってしまう。そのため、年ごとで分けるのが適切かと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引っ越し件数0の部分(→休業日と判明)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y==0、close==1のデータを抽出。引っ越し件数が0件または休業日の場合\n",
    "with pl.Config(tbl_rows=-1):\n",
    "    print(\n",
    "        \"train\\n\", \n",
    "        train.filter(\n",
    "            (pl.col(\"y\") == 0) | (pl.col(\"close\") == 1)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y=0の部分についてのコメント  \n",
    "- これは…お盆のときと、年末年始(12/31~1/3)のときに全く引っ越しがないっぽいな。毎年そうみたい\n",
    "- y=0の部分は機械学習に任せるのではなく、ルールベースで決めてしまったほうが良いだろう\n",
    "- よく見ると、休業日(close==1)とほぼ一致している。年末年始は毎年休業日かつ引っ越し0\n",
    "  - ただし、2010年、2011年のお盆は休業日じゃないけど引っ越し件数0。2012年以降はお盆も休業日になった模様？\n",
    "\n",
    "休業日の場合についてのコメント  \n",
    "- 休業日(close==1)の場合は全てy==0。これはもうルールベースで書いてしまった方が良いかな\n",
    "- お盆は…どうなんだろう。今後お盆が休業日じゃなくなる日ってあるんだろうか？\n",
    "  - お盆は毎年日にちが異なるので…日時でルールを決めるの難しそう\n",
    "  - うーん、close==1を使ってルールを決めるのにとどめたほうがいいかな？\n",
    "  - 2010年だけ例外的にお盆も営業していた？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 休業日の場合は引っ越し数0。これはルールベースで予測することとする。そのため学習からは除外\n",
    "\n",
    "# trainからpl.col(\"y\"==0)である部分を除外する\n",
    "# 2010-08-18と2011-08-14はお盆であるものの休業日に設定されていなかったが、\n",
    "# 以降の年では休業日に設定されたみたいなので学習からは取り除いておく\n",
    "train = train.filter(\n",
    "    (pl.col(\"close\") != 1)\n",
    "    & (pl.col(\"id\") != \"2010-08-18\")\n",
    "    & (pl.col(\"id\") != \"2011-08-14\")\n",
    ")\n",
    "\n",
    "# test_close: testデータの中で休業日の部分(pl.col(\"close\"==1))を抜き出し、\n",
    "# その日は引っ越し数0(pl.col(\"y\"==0))であるとしたdataframe\n",
    "# 元のtestからはその部分は取り除いておく\n",
    "test_close = test.filter(pl.col(\"close\") == 1)[[\"id\"]]\n",
    "test_close = test_close.with_columns(pl.Series(\"y\", [0.0] * len(test_close)))\n",
    "test = test.filter(pl.col(\"close\") != 1)\n",
    "\n",
    "# ちゃんと休業日関連が消せているか確認\n",
    "with pl.Config(tbl_rows=-1):\n",
    "    print(\n",
    "        \"train\\n\",\n",
    "        train.filter(\n",
    "            (pl.col(\"y\") == 0) | (pl.col(\"close\") == 1)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"test\\n\",\n",
    "        test.filter(\n",
    "            (pl.col(\"close\") == 1)\n",
    "        )\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分離が済んだので、close列は削除\n",
    "train = train.drop(\"close\")\n",
    "test = test.drop(\"close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clientフラグについて"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(12, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "plt.suptitle(\"clientフラグについて\\n引越し数 y の推移と分布\")\n",
    "\n",
    "axes[0].set_title(\"推移\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "sns.histplot(data=train, x=\"y\", hue=\"client\", ax=axes[1])\n",
    "\n",
    "axes[1].set_title(\"分布\")\n",
    "sns.lineplot(data=train, x=\"datetime\", y=\"y\", hue=\"client\", ax=axes[0])\n",
    "\n",
    "plt.show()\n",
    "print(train.filter(pl.col(\"client\") == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014年5月からclient(法人が絡む特殊な引越し日フラグ)に関する何かが始まっているみたい  \n",
    "それが何のことなのかは良くわからんけど…日にちに対してフラグが立っている  \n",
    "→多分、「この日は法人からの依頼があった」ということ？yの内何件がそれだったのかはわからんけど⋯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 期間を絞り込んで表示。\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(12, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "plt.suptitle(\"clientフラグについて\\n引越し数 y の推移と分布(2014-05-01以降)\")\n",
    "\n",
    "axes[0].set_title(\"推移\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "sns.histplot(data=train.filter(pl.col(\"datetime\") >= date(2014, 5, 1)), x=\"y\", hue=\"client\", ax=axes[1])\n",
    "\n",
    "axes[1].set_title(\"分布\")\n",
    "sns.lineplot(data=train.filter(pl.col(\"datetime\") >= date(2014, 5, 1)), x=\"datetime\", y=\"y\", hue=\"client\", ax=axes[0])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"client=1(法人あり)のときの引っ越し数yの平均\",\n",
    "      np.round(train.filter(pl.col(\"datetime\") >= date(2014, 5, 1))\n",
    "               .filter(pl.col(\"client\") == 1)[\"y\"].mean(), decimals=2)\n",
    "      )\n",
    "print(\"client=0(通常時)のときの引っ越し数yの平均\",\n",
    "      np.round(train.filter(pl.col(\"datetime\") >= date(2014, 5, 1))\n",
    "               .filter(pl.col(\"client\") == 0)[\"y\"].mean(), decimals=2)\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client=1のときは、そうでないときと比べて引っ越し数が通常より多めの傾向になっている  \n",
    "とはいえそこまで顕著ではないようにも思うが…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 料金区分(午前、午後)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_color = px.colors.sequential.Magma_r\n",
    "# https://oeconomicus.jp/2021/07/plotly-color-scale/\n",
    "\n",
    "# pandas 化\n",
    "df = train.to_pandas().copy()\n",
    "\n",
    "# すべてのカテゴリ（午前/午後の和集合）で色を固定\n",
    "cats_all = sorted(set(df[\"price_am\"].unique()) | set(df[\"price_pm\"].unique()))\n",
    "colors = graph_color[:len(cats_all)]\n",
    "# Plotlyのcolor_discrete_mapはキーが文字列比較になることが多いので安全のため文字列化\n",
    "color_map = {str(c): colors[i] for i, c in enumerate(cats_all)}\n",
    "\n",
    "# 描画用に文字列列を用意（凡例名/trace.nameの一致を安定させる）\n",
    "df[\"price_am_str\"] = df[\"price_am\"].astype(str)\n",
    "df[\"price_pm_str\"] = df[\"price_pm\"].astype(str)\n",
    "\n",
    "# 大枠（2行×2列）\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    row_heights=[0.5, 0.5],\n",
    "    column_widths=[0.7, 0.3],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.05,\n",
    "    subplot_titles=(\"午前: 推移\", \"午前: 分布\", \"午後: 推移\", \"午後: 分布\"),\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1500,\n",
    "    height=900,\n",
    "    title_text=\"午前/午後 料金区分別<br>引越し数 y の推移と分布\",\n",
    "    showlegend=True,\n",
    "    legend_tracegroupgap=12,\n",
    ")\n",
    "\n",
    "# 指定された行に対して、左に推移(scatter)、右に分布(histogram)を追加する関数\n",
    "def add_section(colname_str: str, row: int):\n",
    "    # 左：推移（scatter）\n",
    "    scatter_fig = px.scatter(\n",
    "        df, x=\"datetime\", y=\"y\", color=colname_str,\n",
    "        category_orders={colname_str: [str(c) for c in cats_all]},\n",
    "        color_discrete_map=color_map,\n",
    "    )\n",
    "    for tr in scatter_fig.data:\n",
    "        # カテゴリごとに legendgroup を統一\n",
    "        tr.legendgroup = tr.name                  # カテゴリ単位のグループ化\n",
    "        # tr.marker.symbol = \"cross\"               # マーカー形状を変更 https://plotly.com/python/marker-style/\n",
    "        tr.showlegend = (row == 1)               # 凡例は上段のみ表示\n",
    "        fig.add_trace(tr, row=row, col=1)\n",
    "\n",
    "    # 右：分布（histogram）\n",
    "    hist_fig = px.histogram(\n",
    "        df, x=\"y\", color=colname_str,\n",
    "        category_orders={colname_str: [str(c) for c in cats_all]},\n",
    "        color_discrete_map=color_map,\n",
    "    )\n",
    "    for tr in hist_fig.data:\n",
    "        tr.legendgroup = tr.name                 # 同じカテゴリ名でグルーピング\n",
    "        tr.showlegend = False                    # 凡例は出さないが連動はする\n",
    "        fig.add_trace(tr, row=row, col=2)\n",
    "\n",
    "    # 軸ラベル\n",
    "    fig.update_xaxes(title_text=\"datetime\", row=row, col=1)\n",
    "    fig.update_yaxes(title_text=\"y\",        row=row, col=1)\n",
    "    fig.update_xaxes(title_text=\"y\",        row=row, col=2)\n",
    "    fig.update_yaxes(title_text=\"count\",    row=row, col=2)\n",
    "\n",
    "# 上段: 午前\n",
    "add_section(\"price_am_str\", row=1)\n",
    "# 下段: 午後\n",
    "add_section(\"price_pm_str\", row=2)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "del df, cats_all, colors, color_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-1は欠損。0~5で数値が高いほど料金が高い  \n",
    "グラフより、yが小さいところは料金を低くしており、yが高いところは料金が高くなっていることが分かる  \n",
    "説明通り、繁忙期は料金を高くして調整しようとしていることが見て取れる  \n",
    "所々、料金設定ミスっているところもある？(料金設定高めなのにy低め)  \n",
    "あと、2010年の料金区分のデータが欠損している？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2010年のデータ数\",\n",
    "      len(train.filter(pl.col(\"datetime\") <= date(2010, 12, 31)))\n",
    "      )\n",
    "print(\"2010年でprice_am=-1(欠損)となっているデータ数\",\n",
    "      len((train.filter(pl.col(\"datetime\") <= date(2010, 12, 31))).filter(pl.col(\"price_am\") == -1))\n",
    "      )\n",
    "print(\"2010年でprice_pm=-1(欠損)となっているデータ数\",\n",
    "      len((train.filter(pl.col(\"datetime\") <= date(2010, 12, 31))).filter(pl.col(\"price_pm\") == -1))\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2010年のデータは料金設定という大事なデータが欠損しているため、学習からは外すべし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 料金区分price_am, price_pmが3以上のものを詳しく見てみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 料金区分price_am, price_pmが3以上のものを詳しく見てみる\n",
    "# そこまで数は多くなさそうなので全件表示\n",
    "with pl.Config(tbl_rows=-1):\n",
    "    print(\n",
    "        train.filter(\n",
    "            (pl.col(\"price_am\") >= 3) | (pl.col(\"price_pm\") >= 3)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3月、4月に高めの料金設定をしていることが見て取れる  \n",
    "\n",
    "ただ一点、気になる部分あり  \n",
    "│ id         ┆ datetime   ┆ y   ┆ y_ln     ┆ client ┆ price_am ┆ price_pm │  \n",
    "│ 2011-12-30 ┆ 2011-12-30 ┆ 15  ┆ 2.70805  ┆ 0      ┆ 1        ┆ 3        │  \n",
    "ってなってるけど、これは年末に一応営業したけど午後はスタッフ全然居ないから値付けを高くして調整しようとしたのか？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# トレンドを捉える(prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年を経るごとにyが上昇していくため、yの分布がどんどん右にシフトしていく問題に対処したい\n",
    "# そこで、prophetによる時系列予測によってyのトレンドを予測し、yのトレンドを除去する\n",
    "\n",
    "# polarsのdatetime型をpandasのdatetime型に変換する必要がある\n",
    "## 訓練データ\n",
    "train_pandas = (\n",
    "    train\n",
    "    .select([\"datetime\", \"y\"])\n",
    "    .rename({\"datetime\": \"ds\", \"y\": \"y\"})\n",
    "    .to_pandas().copy()\n",
    ")\n",
    "## テストデータ。datetimeカラムを渡すだけ\n",
    "test_pandas = (\n",
    "    test\n",
    "    .select([\"datetime\"])\n",
    "    .rename({\"datetime\": \"ds\"})\n",
    "    .to_pandas().copy()\n",
    ")\n",
    "\n",
    "# 学習。prophetでは年を超えた全体的なトレンドだけを捉えたいので、seasonalityは全てFalseにする\n",
    "model = Prophet(\n",
    "    yearly_seasonality=False,\n",
    "    weekly_seasonality=False,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='additive'\n",
    ")\n",
    "model.fit(train_pandas)\n",
    "\n",
    "# 予測\n",
    "# グラフ描画用\n",
    "forecast_train = model.predict(train_pandas)\n",
    "forecast_test = model.predict(test_pandas)\n",
    "\n",
    "# 元データへの結合用\n",
    "forecast_train_pl = pl.Series(\"y_trend\", model.predict(train_pandas)[\"yhat\"].values)\n",
    "\n",
    "# trainの方にjoinして列追加\n",
    "train = train.with_columns(forecast_train_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果の可視化\n",
    "fig, ax = plt.subplots(\n",
    "    figsize=(12, 5),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "ax.set_title(\"Prophetによる予測（Train=青, Test=赤）\")\n",
    "\n",
    "# train側は Prophet の標準描画（青・点群付き）\n",
    "model.plot(model.predict(train_pandas), ax=ax)\n",
    "\n",
    "# test側は後から重ね描き（赤）\n",
    "ax.plot(\n",
    "    forecast_test[\"ds\"], forecast_test[\"yhat\"],\n",
    "    color=\"red\", linewidth=2, label=\"Test yhat\"\n",
    ")\n",
    "ax.fill_between(\n",
    "    forecast_test[\"ds\"],\n",
    "    forecast_test[\"yhat_lower\"], forecast_test[\"yhat_upper\"],\n",
    "    color=\"red\", alpha=0.2, label=\"Test interval\"\n",
    ") \n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# 後で再宣言しちゃいそうな変数はここで一度削除\n",
    "del train_pandas, test_pandas, forecast_train, forecast_test, forecast_train_pl, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コメント\n",
    "- 全体的な上昇傾向が上手く捉えられている\n",
    "- testデータの期間についても、尤もらしい傾向が出力できているように思う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トレンドとの残差を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差列、曜日・月列を追加\n",
    "train = train.with_columns(\n",
    "    (pl.col(\"y\") - pl.col(\"y_trend\")).alias(\"y_resid\"),\n",
    "    pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n",
    "    pl.col(\"datetime\").dt.month().alias(\"month\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレンドとの差分を取ることで、年ごとの分布のズレが解消されるか確認する\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=2,\n",
    "    height_ratios=[1, 1], width_ratios=[2, 1],\n",
    "    figsize=(12, 8),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"引越し数の推移と分布。元データ(上段)とトレンドとの残差(下段)の比較\")\n",
    "\n",
    "# 上段。そのまま\n",
    "axes[0, 0].set_title(\"推移\")\n",
    "axes[0, 0].tick_params(axis=\"x\", rotation=90)\n",
    "sns.lineplot(data = train, x=\"datetime\", y=\"y\", hue=\"year\",palette=\"deep\", ax=axes[0, 0])\n",
    "sns.lineplot(data = train, x=\"datetime\", y=\"y_trend\", color=\"0.1\", ax=axes[0, 0])\n",
    "\n",
    "axes[0, 1].set_title(\"分布\")\n",
    "sns.histplot(data = train, x=\"y\", hue=\"year\", palette=\"deep\", ax=axes[0, 1])\n",
    "\n",
    "# 下段。差分\n",
    "axes[1, 0].set_title(\"推移(残差)\")\n",
    "axes[1, 0].tick_params(axis=\"x\", rotation=90)\n",
    "sns.scatterplot(data = train, x=\"datetime\", y=\"y_resid\", hue=\"year\", palette=\"deep\", marker=\"+\", ax=axes[1, 0])\n",
    "\n",
    "axes[1, 1].set_title(\"分布(残差)\")\n",
    "sns.histplot(data = train, x=\"y_resid\", hue=\"year\", palette=\"deep\", ax=axes[1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コメント\n",
    "- 狙い通り、うまい具合に年ごとの分布の中心が揃った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体としての分布がどう変わったかも確認\n",
    "skew_resid = stats.skew(train[\"y_resid\"])\n",
    "kurt_resid = stats.kurtosis(train[\"y_resid\"])\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(12, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"引っ越し数yのトレンドとの残差の推移と分布\")\n",
    "\n",
    "# 下段。差分\n",
    "axes[0].set_title(\"推移(残差)\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=90)\n",
    "sns.scatterplot(data = train, x=\"datetime\", y=\"y_resid\", marker=\"+\", ax=axes[0])\n",
    "\n",
    "axes[1].set_title(\"分布(残差)\")\n",
    "sns.histplot(data = train, x=\"y_resid\", ax=axes[1])\n",
    "axes[1].text(0.6, 0.8,\n",
    "                f\"skewness={skew_resid:.2f}\\nkurtosis={kurt_resid:.2f}\",\n",
    "                fontsize=12,\n",
    "                transform=axes[1].transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コメント\n",
    "- 分布の対称性は改善したが、正規分布に近づいたわけではない\n",
    "- 上昇トレンドは排除出来たが、分散の増大傾向もある模様(不均一分散)。数値変換によって抑えてやる必要があるだろう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 曜日・月ごとの残差分布を確認\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1],\n",
    "    width_ratios=[1,1],\n",
    "    figsize=(8, 4),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "# fig.suptitle(\"\")\n",
    "\n",
    "axes[0].set_title(\"曜日別の残差分布\")\n",
    "sns.boxplot(x=\"weekday\", y=\"y_resid\", data=train, ax=axes[0])\n",
    "\n",
    "axes[1].set_title(\"月別の残差分布\")\n",
    "sns.boxplot(x=\"month\", y=\"y_resid\", data=train, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コメント\n",
    "- 火・水・木は受注減りがち。土日は受注多め\n",
    "- 繁忙期である3~4月は確かに通常期よりも受注が多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数値変換を試す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lightGBMのようなノンパラメトリックなモデルでは分布の形はあまり関係ないが、  \n",
    "それでも分散が増大していく傾向は抑えないといけない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値変換の定義（カラム名, 変換式）\n",
    "transforms = {\n",
    "    \"y_ln\": pl.col(\"y\").log(),\n",
    "    \"y_bc_1_2\": (pl.col(\"y\").pow(1/2) - 1) / (1/2),\n",
    "    \"y_bc_1_10\": (pl.col(\"y\").pow(1/10) - 1) / (1/10),\n",
    "}\n",
    "\n",
    "moments = {}   # 変換ごとの skew / kurtosis を格納\n",
    "results = {}   # 変換ごとの prophet による予測結果を保存\n",
    "\n",
    "for name, expr in transforms.items():\n",
    "    # 変換列をtrainに追加\n",
    "    train = train.with_columns(expr.alias(name))\n",
    "\n",
    "    # prophet用にpandas化したものを用意\n",
    "    df = (\n",
    "        train\n",
    "        .select([\"datetime\", name])\n",
    "        .rename({\"datetime\": \"ds\", name: \"y\"})\n",
    "        .to_pandas()\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # Prophet モデル学習\n",
    "    model = Prophet(\n",
    "        yearly_seasonality=False,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode=\"additive\",\n",
    "    )\n",
    "    model.fit(df)\n",
    "\n",
    "    # 予測結果を保存\n",
    "    results[name] = model.predict(df)\n",
    "    result_pl = pl.Series(f\"{name}_trend\", results[name][\"yhat\"].values)\n",
    "\n",
    "    # trainに予測結果を追加\n",
    "    train = train.with_columns(result_pl)\n",
    "    \n",
    "    # 残差列を追加\n",
    "    train = train.with_columns(\n",
    "        (pl.col(name) - pl.col(f\"{name}_trend\")).alias(f\"{name}_resid\")\n",
    "    )\n",
    "\n",
    "    # 統計量を計算したい列を選択\n",
    "    x = train[f\"{name}_resid\"].to_numpy()\n",
    "    # bias=False で標本推定、fisher=True で excess（正規=0）\n",
    "    moments[name] = {\n",
    "        \"skew\": float(stats.skew(x, bias=True)),\n",
    "        \"kurt\": float(stats.kurtosis(x, fisher=True, bias=True)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描画\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=len(transforms), ncols=2,\n",
    "    height_ratios=[1, 1, 1], width_ratios=[2, 1],\n",
    "    figsize=(15, 4 * len(transforms)),\n",
    "    constrained_layout=True,\n",
    ")\n",
    "fig.suptitle(\"各種数値変換を行った y の、トレンドとの残差の推移と分布\", fontsize=16)\n",
    "\n",
    "# ループで各変換を可視化\n",
    "for i, name in enumerate(transforms.keys()):\n",
    "    resid_col = f\"{name}_resid\"\n",
    "\n",
    "    # --- 残差の推移 ---\n",
    "    axes[i, 0].set_title(f\"推移 ({name})\")\n",
    "    sns.lineplot(\n",
    "        data=train.to_pandas(),\n",
    "        x=\"datetime\", y=resid_col,\n",
    "        ax=axes[i, 0], linewidth=1\n",
    "    )\n",
    "    axes[i, 0].axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # --- 残差の分布 ---\n",
    "    axes[i, 1].set_title(f\"分布 ({name})\")\n",
    "    sns.histplot(\n",
    "        data=train.to_pandas(),\n",
    "        x=resid_col,\n",
    "        kde=True, stat=\"density\",\n",
    "        ax=axes[i, 1],\n",
    "    )\n",
    "    axes[i, 1].axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "    # skew / kurt を表示\n",
    "    m = moments[name]\n",
    "    axes[i, 1].text(\n",
    "        0.05, 0.95,\n",
    "        f\"skew={m['skew']:.2f}\\nkurt={m['kurt']:.2f}\",\n",
    "        transform=axes[i, 1].transAxes,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        fontsize=11, color=\"black\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "グラフについてのコメント\n",
    "- どれも数値変換前の歪度・尖度と比べると正規分布に近づいたが、もう少しいい感じに変換できる設定はないだろうか？\n",
    "  - TODO: 自動でλ等の最適な値を計算してくれる方法があった気がする\n",
    "- とはいえ、分散の増大を抑えたいだけならどれでも良いだろう\n",
    "\n",
    "独り言\n",
    "- polars↔pandasの行ったり来たりが非常に面倒。可視化が絡むEDAでは、polarsを使っていることが非常に重い足枷になる印象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 没：y_residを数値変換→分析といった順番でやった版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_residを数値変換→残差分析といった順番でやった版。尖度・歪度がおかしくなったので没\n",
    "\n",
    "# # 数値変換の定義（カラム名, 変換式）\n",
    "# transforms = {\n",
    "#     \"y_resid_ln\": pl.col(\"y_resid\").log(),\n",
    "#     \"y_resid_bc_1_2\": (pl.col(\"y_resid\").pow(1/2) - 1) / (1/2),\n",
    "#     \"y_resid_bc_1_10\": (pl.col(\"y_resid\").pow(1/10) - 1) / (1/10),\n",
    "# }\n",
    "\n",
    "# moments = {}   # 変換ごとの skew / kurtosis を格納\n",
    "# results = {}   # 変換ごとの prophet による予測結果を保存\n",
    "\n",
    "# for name, expr in transforms.items():\n",
    "#     # 変換列をtrainに追加\n",
    "#     train = train.with_columns(expr.alias(name))\n",
    "\n",
    "#     # 統計量を計算\n",
    "#     x = train[name].to_numpy()\n",
    "#     # bias=False で標本推定、fisher=True で excess（正規=0）\n",
    "#     moments[name] = {\n",
    "#         \"skew\": float(stats.skew(x, bias=False)),\n",
    "#         \"kurt\": float(stats.kurtosis(x, fisher=True, bias=False)),\n",
    "#     }\n",
    "\n",
    "# # 描画設定\n",
    "# fig, axes = plt.subplots(\n",
    "#     nrows=len(transforms), ncols=2,\n",
    "#     figsize=(15, 4 * len(transforms)),\n",
    "#     constrained_layout=True,\n",
    "# )\n",
    "# fig.suptitle(\"各種数値変換を行った y の、トレンドとの残差の推移と分布\", fontsize=16)\n",
    "\n",
    "# # ループで各変換を可視化\n",
    "# for i, name in enumerate(transforms.keys()):\n",
    "#     # --- 残差の推移 ---\n",
    "#     axes[i, 0].set_title(f\"推移 ({name})\")\n",
    "#     sns.lineplot(\n",
    "#         data=train.to_pandas(),\n",
    "#         x=\"datetime\", y=name,\n",
    "#         ax=axes[i, 0], linewidth=1\n",
    "#     )\n",
    "#     axes[i, 0].axhline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "#     # --- 残差の分布 ---\n",
    "#     axes[i, 1].set_title(f\"分布 ({name})\")\n",
    "#     sns.histplot(\n",
    "#         data=train.to_pandas(),\n",
    "#         x=name,\n",
    "#         kde=True, stat=\"density\",\n",
    "#         ax=axes[i, 1],\n",
    "#     )\n",
    "#     axes[i, 1].axvline(0, color=\"red\", linestyle=\"--\", linewidth=1)\n",
    "\n",
    "#     # skew / kurt を表示\n",
    "#     m = moments[name]\n",
    "#     axes[i, 1].text(\n",
    "#         0.05, 0.95,\n",
    "#         f\"skew={m['skew']:.2f}\\nkurt={m['kurt']:.2f}\",\n",
    "#         transform=axes[i, 1].transAxes,\n",
    "#         ha=\"left\", va=\"top\",\n",
    "#         fontsize=11, color=\"black\",\n",
    "#         bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
    "#     )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDAのまとめ\n",
    "1. 目的変数yが増加傾向のため、年毎の分布が右にシフトしている。\n",
    "    - to do: 年毎の目的変数yの分布を揃える必要がある。  \n",
    "2. 目的変数yは繁忙期(3月、4月)とそれ以外の時期で分布が異なる\n",
    "3. 休業日close = 1は目的変数y = 0のため、休業日を分離した。\n",
    "4. 目的変数y = 0の分布の右側の裾野が広いので対数変換で裾野を狭めた。\n",
    "5. 法人対応clientを2014年度から始めた\n",
    "6. 法人が絡む特殊な引越しを行う場合(close = 1)、目的変数の平均値が約9増える\n",
    "7. 料金区分(price_amとprice_pm)は、繁忙期に高い価格を設定している\n",
    "8. 2010年の料金区分が全て欠測値のため削除した\n",
    "9. 午後の料金区分は午前よりも安い傾向にある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考サイト  \n",
    "[コンペサイト アップル 引越し需要予測](https://signate.jp/competitions/269/data)  \n",
    "[SIGNATE SOTA アップル 引越し需要予測 備忘録](https://zenn.dev/tremendous1192/articles/ea6e73359ee764)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# htmlに変換したものを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "base_name = \"EDA\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = Path(\"html\")\n",
    "output_file = f\"{base_name}_{timestamp}\"\n",
    "\n",
    "!jupyter nbconvert --to html EDA.ipynb --output \"{output_file}\" --output-dir \"{output_dir}\""
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb",
   "notebook_metadata_filter": "kernelspec,jupytext"
  },
  "kernelspec": {
   "display_name": "venv_apple_hikkosi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
