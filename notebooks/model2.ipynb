{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ノートブックの概要\n",
    "- 特徴量を追加\n",
    "- モデルはlightGBM\n",
    "- パラメータチューニングなし"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "pl.Config.set_fmt_str_lengths(100)\n",
    "pl.Config.set_tbl_cols(100)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import date\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import jpholiday\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA2までの処理をまとめたもの\n",
    "\n",
    "# データを読み込む\n",
    "train = pl.read_csv(\"../data/input/train.csv\")\n",
    "test = pl.read_csv(\"../data/input/test.csv\")\n",
    "sample_submit = pl.read_csv(\"../data/input/sample_submit.csv\", has_header = False)\n",
    "\n",
    "# IDと日時を分散する\n",
    "train = train.insert_column(0, train[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype = pl.Date))\n",
    "test = test.insert_column(0, test[\"datetime\"].alias(\"id\")).with_columns(pl.col(\"datetime\").str.strptime(dtype = pl.Date))\n",
    "\n",
    "# 休業日(close = 1)(と、お盆だけど休業していなくて結局引っ越し数0だった日)を分離する\n",
    "train = train.filter(\n",
    "    (pl.col(\"close\") != 1)\n",
    "    & (pl.col(\"id\") != \"2010-08-18\")\n",
    "    & (pl.col(\"id\") != \"2011-08-14\")\n",
    ")\n",
    "test_close = test.filter(pl.col(\"close\") == 1)[[\"id\"]]\n",
    "test_close = test_close.with_columns(pl.Series(\"y\", [0.0] * len(test_close)))\n",
    "test = test.filter(pl.col(\"close\") != 1)\n",
    "\n",
    "# 目的変数を対数変換する\n",
    "train = train.insert_column(3, train[\"y\"].log().alias(\"y_ln\"))\n",
    "\n",
    "# closeをカラムごと削除\n",
    "train = train.drop(\"close\")\n",
    "test = test.drop(\"close\")\n",
    "\n",
    "# 2010年は料金区分に関する情報が欠損しているので学習から削除\n",
    "train = train.filter(pl.col(\"datetime\") >= date(2011, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 思いつく限りの特徴量を追加\n",
    "# 今後の運用を考えると、任意の日時について自動でフラグを取得できる必要がある。要改善\n",
    "\n",
    "# 祝日\n",
    "holiday_list = []\n",
    "for pair in jpholiday.between(date(2010, 1, 1), date(2017, 12, 31)):\n",
    "    # print(pair)\n",
    "    holiday_list.append(pair[0])\n",
    "\n",
    "# その他の休日\n",
    "# GW\n",
    "# https://9rando.info/j-holiday/gw/2011/\n",
    "gw_list = [\n",
    "    date(2011, 4, 29), date(2011, 4, 30), date(2011, 5, 1),\n",
    "    date(2011, 5, 2),# 有給休暇の可能性\n",
    "    date(2011, 5, 3), date(2011, 5, 4), date(2011, 5, 5),\n",
    "\n",
    "    date(2012, 4, 28), date(2012, 4, 29), date(2012, 4, 30), date(2012, 5, 1),\n",
    "    date(2012, 5, 2),# 有休\n",
    "    date(2012, 5, 3), date(2012, 5, 4), date(2012, 5, 5), date(2012, 5, 5),\n",
    "\n",
    "    date(2013, 4, 27), date(2013, 4, 28), date(2013, 4, 29),\n",
    "    date(2013, 4, 30), date(2013, 5, 1), date(2013, 5, 2),# 有休\n",
    "    date(2013, 5, 3), date(2013, 5, 4), date(2013, 5, 5), date(2013, 5, 5), date(2013, 5, 6),\n",
    "\n",
    "    date(2014, 4, 29),\n",
    "    date(2014, 4, 30), date(2014, 5, 1), date(2014, 5, 2),# 有休\n",
    "    date(2014, 5, 3), date(2014, 5, 4), date(2014, 5, 5), date(2014, 5, 5), date(2014, 5, 6),\n",
    "\n",
    "    date(2015, 4, 29),\n",
    "    date(2015, 4, 30), date(2015, 5, 1),# 有休\n",
    "    date(2015, 5, 2), date(2015, 5, 3), date(2015, 5, 4), date(2015, 5, 5), date(2015, 5, 5), date(2015, 5, 6),\n",
    "\n",
    "    date(2016, 4, 29), date(2016, 4, 30), date(2016, 5, 1),\n",
    "    date(2016, 5, 2),# 有休\n",
    "    date(2016, 5, 3), date(2016, 5, 4), date(2016, 5, 5),\n",
    "\n",
    "    date(2017, 4, 29), date(2017, 4, 30),\n",
    "    date(2017, 5, 1), date(2017, 5, 2),# 有休\n",
    "    date(2017, 5, 3), date(2017, 5, 4), date(2017, 5, 5), date(2017, 5, 6), date(2017, 5, 7),\n",
    "]\n",
    "\n",
    "# お盆\n",
    "# https://9rando.info/j-holiday/obon/2011/\n",
    "obon_list = [\n",
    "    date(2011, 8, 13), date(2011, 8, 14), date(2011, 8, 15), date(2011, 8, 16),\n",
    "    date(2012, 8, 13), date(2012, 8, 14), date(2012, 8, 15), date(2012, 8, 16),\n",
    "    date(2013, 8, 13), date(2013, 8, 14), date(2013, 8, 15), date(2013, 8, 16),\n",
    "    date(2014, 8, 13), date(2014, 8, 14), date(2014, 8, 15), date(2014, 8, 16),\n",
    "    date(2015, 8, 13), date(2015, 8, 14), date(2015, 8, 15), date(2015, 8, 16),\n",
    "    date(2016, 8, 13), date(2016, 8, 14), date(2016, 8, 15), date(2016, 8, 16),\n",
    "    date(2017, 8, 13), date(2017, 8, 14), date(2017, 8, 15), date(2017, 8, 16),\n",
    "]\n",
    "\n",
    "# シルバーウィーク\n",
    "# https://9rando.info/j-holiday/sw/2011/\n",
    "sw_list = [\n",
    "    date(2011, 9, 17), date(2011, 9, 18), date(2011, 9, 19),\n",
    "    date(2011, 9, 20), date(2011, 9, 21), date(2011, 9, 22),# 有休\n",
    "    date(2011, 9, 23), date(2011, 9, 24), date(2011, 9, 25),\n",
    "\n",
    "    date(2012, 9, 15), date(2012, 9, 16), date(2012, 9, 17),\n",
    "    date(2012, 9, 18), date(2012, 9, 19), date(2012, 9, 20), date(2012, 9, 21),# 有休\n",
    "    date(2012, 9, 22), date(2012, 9, 23), date(2012, 9, 24),\n",
    "\n",
    "    date(2013, 9, 14),date(2013, 9, 15), date(2013, 9, 16),\n",
    "    date(2013, 9, 17), date(2013, 9, 18), date(2013, 9, 19), date(2013, 9, 20),# 有休\n",
    "    date(2013, 9, 21),date(2013, 9, 22), date(2013, 9, 23),\n",
    "\n",
    "    date(2014, 9, 13), date(2014, 9, 14),date(2014, 9, 15),\n",
    "    date(2014, 9, 16), date(2014, 9, 17), date(2014, 9, 18), date(2014, 9, 19),# 有休\n",
    "    date(2014, 9, 20), date(2014, 9, 21),date(2014, 9, 22),\n",
    "\n",
    "    date(2015, 9, 19), date(2015, 9, 20), date(2015, 9, 21),\n",
    "    date(2015, 9, 22), date(2015, 9, 23),\n",
    "\n",
    "    date(2016, 9, 17), date(2016, 9, 18), date(2016, 9, 19),\n",
    "    date(2016, 9, 20), date(2016, 9, 21),# 有休\n",
    "    date(2016, 9, 22),\n",
    "\n",
    "    date(2017, 9, 16), date(2017, 9, 17), date(2017, 9, 18),\n",
    "    date(2017, 9, 19), date(2017, 9, 20), date(2017, 9, 21), date(2017, 9, 22),# 有休\n",
    "    date(2017, 9, 23), date(2017, 9, 24),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    return(\n",
    "        df\n",
    "        # 日付の基本要素の追加\n",
    "        .with_columns([\n",
    "            # 年、四半期、月\n",
    "            pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "            pl.col(\"datetime\").dt.quarter().alias(\"quarter\"),        \n",
    "            pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "            # 年始から数えて何週目か\n",
    "            pl.col(\"datetime\").dt.week().alias(\"week\"),\n",
    "            # 年始から数えて何日目か\n",
    "            pl.col(\"datetime\").dt.ordinal_day().alias(\"ordinal_day\"),\n",
    "            # その月の何日か\n",
    "            pl.col(\"datetime\").dt.day().alias(\"day\"),        \n",
    "            # その月の何週目か\n",
    "            (pl.col(\"datetime\").dt.day() // 7 + 1).alias(\"week_of_month\"),\n",
    "            # 曜日(月曜日が1、日曜日が6)\n",
    "            pl.col(\"datetime\").dt.weekday().alias(\"day_of_week\"),\n",
    "        ])\n",
    "        # 四半期はじめ・終わり、月はじめ・終わりのフラグ\n",
    "        .with_columns([\n",
    "            pl.when((pl.col(\"month\").is_in([1, 4, 7, 10])) & (pl.col(\"day\") == 1)).then(1).otherwise(0)\n",
    "            .alias(\"quarter_start\"),\n",
    "            pl.when((pl.col(\"month\").is_in([3, 6, 9, 12])) & (pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end())).then(1).otherwise(0)\n",
    "            .alias(\"quarter_end\"),\n",
    "            pl.when(pl.col(\"day\") == 1).then(1).otherwise(0)\n",
    "            .alias(\"month_start\"),\n",
    "            pl.when(pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end()).then(1).otherwise(0)\n",
    "            .alias(\"month_end\"),    \n",
    "        ])\n",
    "        # 祝日・休日・土日フラグ\n",
    "        .with_columns([\n",
    "            pl.when(pl.col(\"datetime\").is_in(holiday_list)).then(1).otherwise(0)\n",
    "            .alias(\"holiday\"),\n",
    "            pl.when(pl.col(\"datetime\").is_in(gw_list)).then(1).otherwise(0)\n",
    "            .alias(\"GW\"),\n",
    "            pl.when(pl.col(\"datetime\").is_in(sw_list)).then(1).otherwise(0)\n",
    "            .alias(\"SW\"),\n",
    "            pl.when(pl.col(\"datetime\").is_in(obon_list)).then(1).otherwise(0)\n",
    "            .alias(\"obon\"),\n",
    "            pl.when(pl.col(\"datetime\").dt.weekday() >= 6).then(1).otherwise(0)\n",
    "            .alias(\"sat_sun\"),\n",
    "        ])\n",
    "        # 価格の和・差・積\n",
    "        .with_columns([\n",
    "            (pl.col(\"price_am\") + pl.col(\"price_pm\")).alias(\"price_sum\"),\n",
    "            (pl.col(\"price_am\") - pl.col(\"price_pm\")).alias(\"price_difference\"),\n",
    "            # price = -1が欠損、price = 0は最安価格であった。price同士をそのまま乗算しまうと最安値のときに必ず積が0になってしまうので都合が良くない\n",
    "            # price + 1とすることでこれを回避する。なお、欠損がある場合は積は必ず0となる。これはこれで良いフラグかもしれない？\n",
    "            ((pl.col(\"price_am\") + 1) * (pl.col(\"price_pm\") + 1)).alias(\"price_product\"),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "del holiday_list, gw_list, sw_list, obon_list\n",
    "\n",
    "# display(train)\n",
    "# display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prophetによるベースライン作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年を経るごとにyが上昇していくため、yの分布がどんどん右にシフトしていく問題に対処したい\n",
    "# そこで、prophetによる時系列予測によってyのトレンドを予測し、yのトレンドを除去する\n",
    "\n",
    "# polarsのdatetime型をpandasのdatetime型に変換する必要がある\n",
    "# 訓練データ\n",
    "train_pandas = (\n",
    "    train\n",
    "    .select([\"datetime\", \"y_ln\"])\n",
    "    .rename({\"datetime\": \"ds\", \"y_ln\": \"y\"})\n",
    "    .to_pandas()\n",
    ")\n",
    "# テストデータ\n",
    "test_pandas = (\n",
    "    test\n",
    "    .select([\"datetime\"])\n",
    "    .rename({\"datetime\": \"ds\"})\n",
    "    .to_pandas()\n",
    ")\n",
    "# 学習\n",
    "model = Prophet()\n",
    "model.fit(train_pandas)\n",
    "\n",
    "# 推定値の算出\n",
    "forecast_train = pl.Series(\"y_ln_prophet\", model.predict(train_pandas)[\"yhat\"].values)\n",
    "forecast_test = pl.Series(\"y_ln_prophet\", model.predict(test_pandas)[\"yhat\"].values)\n",
    "\n",
    "# 推定値をDataFrameにまとめる\n",
    "train = train.insert_column(4, forecast_train)\n",
    "test = test.insert_column(3, forecast_test)\n",
    "\n",
    "# 対数変換した目的変数とProphetによる予測値の差分を計算する\n",
    "train = train.insert_column(5, (train[\"y_ln\"] - train[\"y_ln_prophet\"]).alias(\"y_ln_difference\"))\n",
    "\n",
    "# 不要なDataFrameを削除\n",
    "del train_pandas\n",
    "del test_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習ライブラリと親和性の高いPandasに変換する\n",
    "train_pandas = train.to_pandas().set_index(\"id\")\n",
    "\n",
    "# 目的変数と特徴量\n",
    "target_column = \"y_ln_difference\"\n",
    "feature_columns = [\n",
    "    'client',\n",
    "    'price_am',\n",
    "    'price_pm',\n",
    "    'year',\n",
    "    'quarter',\n",
    "    'month',\n",
    "    'week',\n",
    "    'ordinal_day',\n",
    "    'day',\n",
    "    'week_of_month',\n",
    "    'day_of_week',\n",
    "    'quarter_start',\n",
    "    'quarter_end',\n",
    "    'month_start',\n",
    "    'month_end',\n",
    "    'holiday',\n",
    "    'GW',\n",
    "    'SW',\n",
    "    'obon',\n",
    "    'sat_sun',\n",
    "    'price_sum',\n",
    "    'price_difference',\n",
    "    'price_product'\n",
    "]\n",
    "\n",
    "# 今回は時系列予測なので、訓練データと評価データを分割する際に、時系列の順番を考慮する必要がある\n",
    "# 今回は、2015年1月1日を境に訓練データと評価データを分割する\n",
    "# 訓練データと検証データを期間で分割\n",
    "train_temp = train_pandas[train_pandas[\"datetime\"] < \"2015-01-01\"]\n",
    "valid_temp = train_pandas[train_pandas[\"datetime\"] >= \"2015-01-01\"]\n",
    "\n",
    "# 説明変数と目的変数を分割\n",
    "X_train, y_train = train_temp[feature_columns], train_temp[target_column]\n",
    "X_valid, y_valid = valid_temp[feature_columns], valid_temp[target_column]\n",
    "\n",
    "# 学習\n",
    "model = GradientBoostingRegressor(random_state = 1192).fit(X_train, y_train)\n",
    "\n",
    "# 予測(モデルの予測値をベースラインであるy_ln_prophetに足した後、対数変換を逆変換)\n",
    "y_pred_train = np.exp(model.predict(X_train) + train_temp[\"y_ln_prophet\"])\n",
    "y_pred_valid = np.exp(model.predict(X_valid) + valid_temp[\"y_ln_prophet\"])\n",
    "\n",
    "# 予測精度の確認\n",
    "print(\"訓練データの評価関数:\", np.round(mean_absolute_error(train_temp[\"y\"], y_pred_train), decimals = 7))# 小数第7位はコンペスコアの有効数字\n",
    "print(\"評価データの評価関数:\", np.round(mean_absolute_error(valid_temp[\"y\"], y_pred_valid), decimals = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果の可視化\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=2,\n",
    "    height_ratios=[1, 1, 1], width_ratios=[2, 1],\n",
    "    figsize=(15, 12)\n",
    ")\n",
    "\n",
    "g_time_train = sns.lineplot(data = train_pandas, x=\"datetime\", y=\"y\", ax=axes[0, 0])\n",
    "g_predict_train = sns.lineplot(data = train_temp, x=\"datetime\", y=y_pred_train, ax=axes[0, 0])\n",
    "g_predict_valid = sns.lineplot(data = valid_temp, x=\"datetime\", y=y_pred_valid, ax=axes[0, 0])\n",
    "\n",
    "g_time_hist_train = sns.histplot(data = train_pandas, x=\"y\", ax=axes[0, 1])\n",
    "g_predict_hist_train = sns.histplot(data = train_temp, x=y_pred_train, ax=axes[0, 1])\n",
    "g_predict_hist_valid = sns.histplot(data = valid_temp, x=y_pred_valid, ax=axes[0, 1])\n",
    "\n",
    "# 残差の確認\n",
    "g_diff_train = sns.scatterplot(data = train_temp, x=\"datetime\", y=train_temp[\"y\"] - y_pred_train, marker = \"+\", ax=axes[1, 0])\n",
    "g_diff_valid = sns.scatterplot(data = valid_temp, x=\"datetime\", y=valid_temp[\"y\"] - y_pred_valid, marker = \"+\", ax=axes[1, 0])\n",
    "axes[1, 0].set_ylabel(\"予測と実際の残差\")\n",
    "\n",
    "g_hist_diff_train = sns.histplot(data = train_temp, x=train_temp[\"y\"] - y_pred_train, bins=50, ax=axes[1, 1])\n",
    "g_hist_diff_valid = sns.histplot(data = valid_temp, x=valid_temp[\"y\"] - y_pred_valid, bins=50, ax=axes[1, 1])\n",
    "\n",
    "# 特徴量重要度\n",
    "g_importance = sns.barplot(x=model.feature_importances_, y=feature_columns, ax=axes[2, 0])\n",
    "g_importance.set_title(\"特徴量重要度\")\n",
    "\n",
    "axes[2, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# ごちゃごちゃしやすい変数たちはここで一度全て削除しておく\n",
    "del train_temp, valid_temp\n",
    "del X_train, y_train, X_valid, y_valid\n",
    "del y_pred_train, y_pred_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "予測値のベースラインっぽいのが消えて、引っ越し数の低いところに対しても予測できるようになった！！  \n",
    "ordinal_dayが強い。年始から数えて何日かなので、時期を表しているのだろう。  \n",
    "\n",
    "ただ、今回の成果物のことを考えると…ピークへの追随が弱い。これでは、「特に繁忙期にどれくらいの需要が来そうか」の予測精度としては弱いか…？  \n",
    "改善のためには、学習の際のスコアを変えてあげれば良いのだろうか？どんなものがあるだろうか？  \n",
    "現状だと、MSEを使って学習をさせている。既に適切な指標を使っているはずではあるが…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提出データ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出前に、全ての訓練データを使って学習させておく\n",
    "X, y = train_pandas[feature_columns], train_pandas[target_column]\n",
    "model = GradientBoostingRegressor(random_state = 1192).fit(X, y)\n",
    "\n",
    "# 機械学習ライブラリと親和性の高いPandasに変換する\n",
    "test_pandas = test.to_pandas().set_index(\"id\")\n",
    "\n",
    "# 説明変数の分割\n",
    "X_test = test_pandas[feature_columns]\n",
    "\n",
    "# 予測\n",
    "y_pred_test = np.exp(model.predict(X_test) + test_pandas[\"y_ln_prophet\"])\n",
    "\n",
    "# 提出用DataFrame\n",
    "submit = pl.DataFrame({\n",
    "    \"id\": X_test.index.values,\n",
    "    \"y\": y_pred_test.values\n",
    "})\n",
    "\n",
    "# 退避していた休業日のデータを結合\n",
    "submit = pl.concat(\n",
    "    [submit, test_close],\n",
    "    how = \"vertical_relaxed\"\n",
    ").sort(\"id\")\n",
    "\n",
    "# 提出ファイルを保存する\n",
    "# submit.write_csv(\"../data/output/submit_add_features_gbt_default_prms.csv\", include_header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対する予測の可視化\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2,\n",
    "    height_ratios=[1], width_ratios=[2, 1],\n",
    "    figsize=(15, 4)\n",
    ")\n",
    "\n",
    "g_time_train = sns.lineplot(data = train_pandas, x=\"datetime\", y=\"y\", ax=axes[0])\n",
    "g_time_test = sns.lineplot(data = test_pandas, x=\"datetime\", y=y_pred_test, ax=axes[0])\n",
    "\n",
    "g_hist_train = sns.histplot(data = train_pandas, x=\"y\", ax=axes[1])\n",
    "g_hist_test = sns.histplot(data = test_pandas, x=y_pred_test, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考サイト  \n",
    "[コンペサイト アップル 引越し需要予測](https://signate.jp/competitions/269/data)  \n",
    "[SIGNATE SOTA アップル 引越し需要予測 備忘録](https://zenn.dev/tremendous1192/articles/ea6e73359ee764)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今後は汎化性能を向上させたい。今は検証データのセットが一つだけ。訓練データに対するスコアと検証データに対する精度の差が激しい。  \n",
    "KFold法みたいなやつを行って汎化性能を上げたいが、時系列予測なので分け方に気をつける必要がある。  \n",
    "時系列予測だと、TimeSeriesSplitとかWalk Forwar Validationとかいうのが使われるらしい。  \n",
    "他にも、パラメータチューニングも未実施なので、その辺りの取り組み余地はある  \n",
    "\n",
    "ただ、250409 11:47 コンペのスコア：8.5537881であり、現時点で十分な精度がでているとも言える。  \n",
    "これ以上の精度向上を求めるより、別の所(顧客の要件を満たす)に注力したほうが良いかも知れない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "てかそういえば、あまり気にしてこなかったけど、この周期的な細かいギザギザは何によって生まれているんだろう？土日とか？  \n",
    "確認してみても良いかも知れない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 退避。特徴量の追加。trainとtestで重複したコードを書いていた頃\n",
    "\n",
    "# train = (\n",
    "#     train\n",
    "#     # 日付の基本要素の追加\n",
    "#     .with_columns([\n",
    "#         # 年、四半期、月\n",
    "#         pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "#         pl.col(\"datetime\").dt.quarter().alias(\"quarter\"),        \n",
    "#         pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "#         # 年始から数えて何週目か\n",
    "#         pl.col(\"datetime\").dt.week().alias(\"week\"),\n",
    "#         # 年始から数えて何日目か\n",
    "#         pl.col(\"datetime\").dt.ordinal_day().alias(\"ordinal_day\"),\n",
    "#         # その月の何日か\n",
    "#         pl.col(\"datetime\").dt.day().alias(\"day\"),        \n",
    "#         # その月の何週目か\n",
    "#         (pl.col(\"datetime\").dt.day() // 7 + 1).alias(\"week_of_month\"),\n",
    "#         # 曜日\n",
    "#         pl.col(\"datetime\").dt.weekday().alias(\"day_of_week\"),\n",
    "#     ])\n",
    "#     # 四半期はじめ・終わり、月はじめ・終わりのフラグ\n",
    "#     .with_columns([\n",
    "#         pl.when((pl.col(\"month\").is_in([1, 4, 7, 10])) & (pl.col(\"day\") == 1)).then(1)\n",
    "#         .otherwise(0).alias(\"quarter_start\"),\n",
    "#         pl.when((pl.col(\"month\").is_in([3, 6, 9, 12])) & (pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end())).then(1)\n",
    "#         .otherwise(0).alias(\"quarter_end\"),\n",
    "#         pl.when(pl.col(\"day\") == 1).then(1)\n",
    "#         .otherwise(0).alias(\"month_start\"),\n",
    "#         pl.when(pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end()).then(1)\n",
    "#         .otherwise(0).alias(\"month_end\"),    \n",
    "#     ])\n",
    "#     # 価格の和・差・積\n",
    "#     .with_columns([\n",
    "#         (pl.col(\"price_am\") + pl.col(\"price_pm\")).alias(\"price_sum\"),\n",
    "#         (pl.col(\"price_am\") - pl.col(\"price_pm\")).alias(\"price_difference\"),\n",
    "#         # price = -1が欠損、price = 0は最安価格であった。price同士をそのまま乗算しまうと最安値のときに必ず積が0になってしまうので都合が良くない\n",
    "#         # price + 1とすることでこれを回避する。なお、欠損がある場合は積は必ず0となる。これはこれで良いフラグかもしれない？\n",
    "#         ((pl.col(\"price_am\") + 1) * (pl.col(\"price_pm\") + 1)).alias(\"price_product\"),\n",
    "#     ])\n",
    "# )\n",
    "# test = (\n",
    "#     test\n",
    "#     # 日付の基本要素の追加\n",
    "#     .with_columns([\n",
    "#         # 年、四半期、月\n",
    "#         pl.col(\"datetime\").dt.year().alias(\"year\"),\n",
    "#         pl.col(\"datetime\").dt.quarter().alias(\"quarter\"),        \n",
    "#         pl.col(\"datetime\").dt.month().alias(\"month\"),\n",
    "#         # 年始から数えて何週目か\n",
    "#         pl.col(\"datetime\").dt.week().alias(\"week\"),\n",
    "#         # 年始から数えて何日目か\n",
    "#         pl.col(\"datetime\").dt.ordinal_day().alias(\"ordinal_day\"),\n",
    "#         # その月の何日か\n",
    "#         pl.col(\"datetime\").dt.day().alias(\"day\"),        \n",
    "#         # その月の何週目か\n",
    "#         (pl.col(\"datetime\").dt.day() // 7 + 1).alias(\"week_of_month\"),\n",
    "#         # 曜日\n",
    "#         pl.col(\"datetime\").dt.weekday().alias(\"day_of_week\"),\n",
    "#     ])\n",
    "#     # 四半期はじめ・終わり、月はじめ・終わりのフラグ\n",
    "#     .with_columns([\n",
    "#         pl.when((pl.col(\"month\").is_in([1, 4, 7, 10])) & (pl.col(\"day\") == 1)).then(1)\n",
    "#         .otherwise(0).alias(\"quarter_start\"),\n",
    "#         pl.when((pl.col(\"month\").is_in([3, 6, 9, 12])) & (pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end())).then(1)\n",
    "#         .otherwise(0).alias(\"quarter_end\"),\n",
    "#         pl.when(pl.col(\"day\") == 1).then(1)\n",
    "#         .otherwise(0).alias(\"month_start\"),\n",
    "#         pl.when(pl.col(\"datetime\") == pl.col(\"datetime\").dt.month_end()).then(1)\n",
    "#         .otherwise(0).alias(\"month_end\"),    \n",
    "#     ])\n",
    "#     # 価格の和・差・積\n",
    "#     .with_columns([\n",
    "#         (pl.col(\"price_am\") + pl.col(\"price_pm\")).alias(\"price_sum\"),\n",
    "#         (pl.col(\"price_am\") - pl.col(\"price_pm\")).alias(\"price_difference\"),\n",
    "#         # price = -1が欠損、price = 0は最安価格であった。price同士をそのまま乗算しまうと最安値のときに必ず積が0になってしまうので都合が良くない\n",
    "#         # price + 1とすることでこれを回避する。なお、欠損がある場合は積は必ず0となる。これはこれで良いフラグかもしれない？\n",
    "#         ((pl.col(\"price_am\") + 1) * (pl.col(\"price_pm\") + 1)).alias(\"price_product\"),\n",
    "#     ])\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb",
   "notebook_metadata_filter": "kernelspec,jupytext"
  },
  "kernelspec": {
   "display_name": "venv_apple_hikkosi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
